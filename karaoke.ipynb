{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from demucs.pretrained import get_model\n",
    "from demucs.apply import apply_model\n",
    "import torchaudio\n",
    "from pathlib import Path\n",
    "import whisper\n",
    "import difflib\n",
    "import json\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# =========================================\n",
    "# FILE_PATH = Path(\"/home/michal/DEV/Karaoke/rower.mp3\")\n",
    "FILE_PATH = Path(\"/home/michal/DEV/Karaoke/youre_the_one_that_i_want.mp3\")\n",
    "# =========================================\n",
    "\n",
    "CACHE_DIR = Path(\"cache\")\n",
    "VOCALS_FILE_PATH = CACHE_DIR / FILE_PATH.stem / f\"{FILE_PATH.stem}.vocals.mp3\"\n",
    "INSTRUMENTAL_FILE_PATH = (\n",
    "    CACHE_DIR / FILE_PATH.stem / f\"{FILE_PATH.stem}.instrumental.mp3\"\n",
    ")\n",
    "LYRICS_FILE_PATH = CACHE_DIR / FILE_PATH.stem / f\"{FILE_PATH.stem}.lyrics.txt\"\n",
    "ALIGNED_LYRICS_FILE_PATH = (\n",
    "    CACHE_DIR / FILE_PATH.stem / f\"{FILE_PATH.stem}.aligned_lyrics.json\"\n",
    ")\n",
    "\n",
    "CACHE_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "\n",
    "print(f\"{CACHE_DIR=}\")\n",
    "print(f\"{FILE_PATH=}\")\n",
    "print(f\"{VOCALS_FILE_PATH=}\")\n",
    "print(f\"{INSTRUMENTAL_FILE_PATH=}\")\n",
    "print(f\"{LYRICS_FILE_PATH=}\")\n",
    "print(f\"{ALIGNED_LYRICS_FILE_PATH=}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_track(path: Path, audio: torch.Tensor, sr: int = 44100):\n",
    "    print(f\"Saving {path}\")\n",
    "    path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    torchaudio.save(path, audio, sample_rate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_audio(file: Path):\n",
    "    model = get_model(\"htdemucs\")\n",
    "    model.eval()\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        model.cuda()\n",
    "\n",
    "    audio, sr = torchaudio.load(file)\n",
    "\n",
    "    # Ensure audio is stereo\n",
    "    if audio.shape[0] == 1:\n",
    "        audio = audio.cat([audio, audio], dim=0)  # Convert mono to stereo\n",
    "    elif audio.shape[0] > 2:\n",
    "        audio = audio[:2]  # Take first two channels if more than stereo\n",
    "    audio = audio.unsqueeze(0)\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        audio = audio.cuda()\n",
    "\n",
    "    with torch.no_grad():\n",
    "        sources = apply_model(model, audio, split=True, progress=True)\n",
    "\n",
    "    # Get the index of vocals\n",
    "    vocals_idx = model.sources.index(\"vocals\")\n",
    "    vocals = sources[0, vocals_idx]\n",
    "    # Sum all other sources for instrumental\n",
    "    instrumental = torch.zeros_like(vocals)\n",
    "    for i, source in enumerate(model.sources):\n",
    "        if i != vocals_idx:  # Skip vocals\n",
    "            instrumental += sources[0, i]\n",
    "\n",
    "    vocals = torch.tanh(vocals * 2) / 2  # Increase vocal presence\n",
    "    vocals = vocals + (vocals - vocals.roll(1, -1)) * 0.5  # Enhance clarity\n",
    "    vocals = vocals + (vocals - vocals.roll(2, -1)) * 0.2  # Enhance harmonicity\n",
    "\n",
    "    if torch.cuda.is_available():\n",
    "        vocals = vocals.cpu()\n",
    "        instrumental = instrumental.cpu()\n",
    "\n",
    "    print(\n",
    "        f\"Saving vocals shape: {vocals.shape}, instrumental shape: {instrumental.shape}\"\n",
    "    )\n",
    "    save_track(VOCALS_FILE_PATH, vocals, sr)\n",
    "    save_track(INSTRUMENTAL_FILE_PATH, instrumental, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_lyrics() -> str:\n",
    "    if LYRICS_FILE_PATH.exists():\n",
    "        with open(LYRICS_FILE_PATH, \"r\") as f:\n",
    "            lyrics = f.read()\n",
    "            lyrics = re.sub(r\"[\\{\\[\\(].*?[\\}\\]\\)]\", \"\", lyrics)\n",
    "            return lyrics\n",
    "    else:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "def transcribe_audio(model_size: str = \"large\") -> dict:\n",
    "    model = whisper.load_model(model_size)\n",
    "    print(\"Transcribing audio...\")\n",
    "    audio_path = str(VOCALS_FILE_PATH)\n",
    "    audio = whisper.load_audio(audio_path)\n",
    "    result = model.transcribe(\n",
    "        audio,\n",
    "        # temperature=0.2,\n",
    "        word_timestamps=True,\n",
    "        # condition_on_previous_text=True,\n",
    "        # initial_prompt=get_lyrics(),\n",
    "        hallucination_silence_threshold=0.1,\n",
    "        # verbose=True,\n",
    "    )\n",
    "    return result\n",
    "\n",
    "\n",
    "# transcribe_audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import TypeVar\n",
    "# from rich import print\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class Word:\n",
    "    text: str\n",
    "    start: float\n",
    "    end: float\n",
    "\n",
    "\n",
    "LyricsSlice = TypeVar(\"LyricsSlice\")\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class LyricsSlice:\n",
    "    words: list[Word]\n",
    "    raw_text: str | None = None\n",
    "\n",
    "    def __str__(self):\n",
    "        return \" \".join(word.text.strip() for word in self.words)\n",
    "\n",
    "    def __add__(self, other): ...\n",
    "\n",
    "    def append(self, slice: LyricsSlice, rebase: bool = True) -> None:\n",
    "        if rebase:\n",
    "            slice.rebase(self.end)\n",
    "        self.words += slice.words\n",
    "\n",
    "    def stretch(self, value: float, backward: bool = False):\n",
    "        duration = self.words[-1].end - self.words[0].start\n",
    "        new_duration = duration + value\n",
    "        scale = new_duration / duration\n",
    "\n",
    "        for word in self.words:\n",
    "            if not backward:\n",
    "                word.start = (\n",
    "                    self.words[0].start + (word.start - self.words[0].start) * scale\n",
    "                )\n",
    "                word.end = (\n",
    "                    self.words[0].start + (word.end - self.words[0].start) * scale\n",
    "                )\n",
    "            else:\n",
    "                word.start = (\n",
    "                    self.words[-1].end - (self.words[-1].end - word.start) * scale\n",
    "                )\n",
    "                word.end = self.words[-1].end - (self.words[-1].end - word.end) * scale\n",
    "\n",
    "    def shift(self, value: float):\n",
    "        for word in self.words:\n",
    "            word.start += value\n",
    "            word.end += value\n",
    "\n",
    "    def rebase(self, base: float):\n",
    "        diff = base - self.start\n",
    "        for word in self.words:\n",
    "            word.start += diff\n",
    "            word.end += diff\n",
    "\n",
    "    @property\n",
    "    def start(self):\n",
    "        return self.words[0].start\n",
    "\n",
    "    @property\n",
    "    def end(self):\n",
    "        return self.words[-1].end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l = LyricsSlice(\n",
    "    [\n",
    "        Word(\"Hello\", 2.0, 3.0),\n",
    "        Word(\"happy\", 3.0, 4.5),\n",
    "        Word(\"world\", 4.6, 5.8),\n",
    "    ],\n",
    ")\n",
    "l2 = LyricsSlice(\n",
    "    [\n",
    "        Word(\"some\", 1.0, 2.0),\n",
    "        Word(\"other\", 2.0, 3.5),\n",
    "        Word(\"text\", 3.6, 4.8),\n",
    "    ]\n",
    ")\n",
    "l.shift(-1.0)\n",
    "l.stretch(2.5, backward=True)\n",
    "l.rebase(0)\n",
    "l.append(l2)\n",
    "print(f\"{l=}\")\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lyrics:\n",
    "    def __init__(self, transcript: dict) -> None:\n",
    "        self.raw_lyrics: list | None = None\n",
    "        self.slices: list[LyricsSlice] = []\n",
    "        self.words = []\n",
    "        for i, seg in enumerate(transcript[\"segments\"]):\n",
    "            for word in transcript[\"segments\"][i][\"words\"]:\n",
    "                self.words.append(\n",
    "                    Word(word[\"word\"].strip(\" ,.!?()[]\"), word[\"start\"], word[\"end\"])\n",
    "                ) if word[\"probability\"] > 0.3 else None\n",
    "\n",
    "    def __repr__(self) -> str:\n",
    "        return \" \".join([word.text for word in self.words])\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        return self.__repr__()\n",
    "\n",
    "    def get_time_slice(self, start: float, end: float) -> LyricsSlice:\n",
    "        result = [\n",
    "            word for word in self.words if word.start >= start and word.end <= end\n",
    "        ]\n",
    "        return LyricsSlice(result)\n",
    "\n",
    "    def get_words_slice(self, start: int, end: int) -> LyricsSlice:\n",
    "        result = self.words[start:end]\n",
    "        return LyricsSlice(result)\n",
    "\n",
    "    def get_text_slice(\n",
    "        self,\n",
    "        text: str,\n",
    "        after: float = None,\n",
    "        similarity_threshold: float = 0.5,\n",
    "    ) -> LyricsSlice:\n",
    "        search_words = [w.strip(\" ,.!?()[]\").lower() for w in text.split()]\n",
    "        if not search_words:\n",
    "            return LyricsSlice([])\n",
    "\n",
    "        search_space = self.words\n",
    "        if after is not None:\n",
    "            search_space = [w for w in self.words if w.start >= after]\n",
    "            if not search_space:\n",
    "                return LyricsSlice([])\n",
    "\n",
    "        # Find the best starting position in self.words that matches our search words\n",
    "        # best_match_start = 0\n",
    "        best_match_score = 0\n",
    "        best_matched_words = []\n",
    "\n",
    "        # Try each possible starting position in self.words\n",
    "        for start_idx in range(len(search_space) - len(search_words) + 1):\n",
    "            current_words = search_space[start_idx : start_idx + len(search_words) + 1]\n",
    "            current_score = 0\n",
    "            matched = []\n",
    "\n",
    "            # Compare each word pair\n",
    "            for search_word, word in zip(search_words, current_words):\n",
    "                # Use difflib to compute similarity\n",
    "                similarity = difflib.SequenceMatcher(\n",
    "                    None, search_word, word.text.lower()\n",
    "                ).ratio()\n",
    "\n",
    "                if similarity >= similarity_threshold:\n",
    "                    current_score += similarity\n",
    "                    matched.append(word)\n",
    "                else:\n",
    "                    matched.append(None)\n",
    "\n",
    "            # Normalize score by number of words\n",
    "            avg_score = current_score / len(search_words)\n",
    "\n",
    "            if avg_score > best_match_score:\n",
    "                best_match_score = avg_score\n",
    "                # best_match_start = start_idx\n",
    "                best_matched_words = matched\n",
    "\n",
    "        # Filter out None values and return the slice\n",
    "        result = [w for w in best_matched_words if w is not None]\n",
    "        return LyricsSlice(result, text)\n",
    "\n",
    "    def get_word_at_time(self, time: float) -> Word:\n",
    "        for word in self.words:\n",
    "            if word.start <= time <= word.end:\n",
    "                return word\n",
    "        return None\n",
    "\n",
    "    def align_lyrics(self, lyrics: str, similarity_threshold: float = 0.5):\n",
    "        self.raw_lyrics = lyrics.splitlines()\n",
    "        self.slices = []\n",
    "        last_slice_end = 0.0\n",
    "        for line in self.raw_lyrics:\n",
    "            slice = self.get_text_slice(\n",
    "                line, after=last_slice_end, similarity_threshold=similarity_threshold\n",
    "            )\n",
    "            # last_slice_end = slice.end if slice.words else 0.0\n",
    "            if slice.words:\n",
    "                last_slice_end = slice.end\n",
    "            else:\n",
    "                # last_slice_end = 0.0\n",
    "                slice = self.get_text_slice(\n",
    "                    line, similarity_threshold=similarity_threshold\n",
    "                )\n",
    "            self.slices.append(slice)\n",
    "        return self.slices\n",
    "\n",
    "    def check_time_overlap(self, slice1, slice2) -> bool:\n",
    "        if slice1.end > slice2.start and slice1.start < slice2.end:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def check_time_continuation(self, slice1, slice2) -> bool:\n",
    "        if slice1.end <= slice2.start:\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "\n",
    "    def check_alignment(self):\n",
    "        for i in range(len(self.slices) - 1):\n",
    "            if self.check_time_overlap(self.slices[i], self.slices[i + 1]):\n",
    "                print(\"Overlap detected:\", self.slices[i], self.slices[i + 1])\n",
    "                return False\n",
    "            if not self.check_time_continuation(self.slices[i], self.slices[i + 1]):\n",
    "                print(\"Continuation problem:\", self.slices[i], self.slices[i + 1])\n",
    "                return False\n",
    "        return True\n",
    "\n",
    "    def fix_alignment(self, max_try: int = 100):\n",
    "        try_num = 0\n",
    "        if not self.check_alignment():\n",
    "            print(\"Fixing alignment...\")\n",
    "            while not self.check_alignment() and try_num < max_try:\n",
    "                try_num += 1\n",
    "                for i in range(len(self.slices) - 1):\n",
    "                    current_slice = self.slices[i]\n",
    "                    next_slice = self.slices[i + 1]\n",
    "\n",
    "                    # if self.check_time_overlap(current_slice, next_slice):\n",
    "                    #     overlap = current_slice.end - next_slice.start\n",
    "                    #     next_slice.shift(overlap)\n",
    "\n",
    "                    if not self.check_time_continuation(current_slice, next_slice):\n",
    "                        gap = next_slice.start - current_slice.end\n",
    "                        print(f\"{gap=}\")\n",
    "                        next_slice.shift(gap)\n",
    "\n",
    "                # self.slices[0].rebase(0)  # Ensure the first slice starts at 0\n",
    "            print(\"Alignment fixed!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "process_audio(FILE_PATH)\n",
    "a = transcribe_audio()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from rich import print\n",
    "\n",
    "lyrics = Lyrics(a)\n",
    "print(lyrics, end=\"\\n\\n\")\n",
    "\n",
    "# slice = lyrics.get_text_slice(\"Are you sure Yes I'm sure down deep inside\")\n",
    "# print(slice)\n",
    "# slice.rebase(10)\n",
    "# print(slice)\n",
    "# slice = lyrics.get_text_slice(\"Are you sure Yes I'm sure down deep inside\")\n",
    "# print(slice)\n",
    "\n",
    "lyrics.align_lyrics(get_lyrics(), similarity_threshold=0.7)\n",
    "lyrics.fix_alignment()\n",
    "# print(lyrics.slices)\n",
    "# l = get_lyrics().splitlines()\n",
    "# for line in l:\n",
    "#     print(line, lyrics.get_text_slice(line, similarity_threshold=0.3), end=\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
